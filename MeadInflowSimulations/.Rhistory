geom_text_contour(data=dfResults, aes(x=InflowToUse/1e6, y= Duration, z = zStorage), binwidth=4, size=6, check_overlap = TRUE, min.size = 5) +
geom_label(data=dfStatusPositionsStor, aes(x = MidInflow/1e6 , y = MaxDuration+2, label = Label, fontface="bold", color=Status), size=6, angle = 0) +
#Plot the Middle groups as contours
#geom_contour(data=dfResultsMid, aes(x=InflowToUse/1e6, y= Duration, z = zStorage, color = Status), binwidth=4, size=1.5)   +
#geom_text_contour(data=dfResultsMid, aes(x=InflowToUse/1e6, y= Duration, z = zStorage), binwidth=4, size=6, check_overlap = TRUE, min.size = 5) +
geom_line(data=dfResultsMid, aes(x=InflowToUse/1e6,y=Duration, color = Status), size=1.5) +
geom_label(data = dfResultsMid %>% filter(Duration==MaxDuration/2), aes(x=InflowToUse/1e6, y=Duration, label = sprintf("%.1f",zStorage), size=5),angle=0) +
#Overplot the data points
#geom_point(data=dfResultsMid, aes(x=InflowToUse/1e6, y= Duration), color="Black", size = 5) +
#Label the polygons
#  geom_label(data=dfPolyLabel, aes(x = xLabelPos, y = MidMead/1e6, label = Label, fontface="bold"), size=6, angle = 0) +
#Y-axis: Active storage on left, Elevation with labels on right
scale_y_continuous(breaks = seq(0,MaxDuration,by=5), labels = seq(0,MaxDuration,by=5), limits = c(0, MaxDuration+3)) +
# sec.axis = sec_axis(~. +0, name = "Mead Level (feet)", breaks = dfMeadPoolsPlot$stor_maf, labels = dfMeadPoolsPlot$labelSecY)) +
scale_x_continuous(breaks = xFlowScaleCurr, labels = xFlowScaleCurr) +
#limits = c(0,as.numeric(dfMaxStor %>% filter(Reservoir %in% c("Mead")) %>% select(Volume))),
#scale_y_continuous(breaks = seq(0,50,by=10), labels = seq(0,50,by=10), limits = c(0, 50)) +
#Color scale for polygons - increasing red as go to lower levels
#scale_fill_manual(breaks = c(2,1),values = c(palReds[3],palReds[2]),labels = dfPolyLabel$Label ) +
scale_fill_manual(guide="Guide2", breaks = c("Top","Middle","Bottom"),values = c("Blue","Green","Red"),labels = c("Fill (years)","Steady volume (maf)","To 1,025 (years)" )) +
scale_color_manual(breaks = c("Top","Middle","Bottom"), values=c("red","purple","blue"), labels=c("To Fill (years)","Steady volume (maf)","To 1,025 (years)")) +
theme_bw() +
scale_size(guide="none") +
labs(x=paste(dfInflowAxes[i,1]," (MAF per year)"), y="Duration (years)") +
#theme(text = element_text(size=20), legend.title=element_blank(), legend.text=element_text(size=18),
#      legend.position = c(0.8,0.7))
theme(text = element_text(size=20),
legend.position = "none")
print(pPlotStor)
sFigNum <- paste("Fig",i+6,"-FlowDurationStorage",sep="")
sFigName <- paste(sFigNum,dfInflowAxes[i,3],sep="")
ggsave(paste(sFigName,".jpg"),width = 12,
height = 7.5, units = "in",
dpi = 300)
# End Loop over axes
#}
### Dummy contour plot for vertical data
dfDummyVertical <- data.frame(InflowToUse = rep(seq(8.5,10.5,by=0.5),3),
Duration = c(rep(1,5),rep(10,5),rep(25,5)),
zStorage = rep(seq(6,14,by=2),3))
relBreaks <- seq(6,14,by=2)
ggplot(dfDummyVertical, aes(x=InflowToUse, y= Duration, z = zStorage)) +
#geom_polygon(data = dfPolyScens, aes(x = Inflow + dfInflowAxes[i,2]/1e6, y = MeadVol/1e6, group = id, fill = as.factor(dfPolyScens$DumVal)), show.legend = F) +
geom_contour2( colour = "black", size=0.75, breaks = relBreaks)   +
#Label contour lines (This is not working very well)
#metR::geom_text_contour(aes(label=..level..),size=6, check_overlap = TRUE, parse = TRUE) +
#geom_dl(aes(label=..level..),method=list("angled.boxes", cex=2), stat="contour", breaks = relBreaks, na.rm = TRUE) +
#geom_dl(aes(label=dfDummyVertical$zStorage),method=list("angled.boxes", cex=2), stat="contour", breaks = relBreaks) +
#Overplot the data points
#geom_point( color="Black", size = 5) +
geom_label(data = dfDummyVertical %>% filter(Duration==10), aes(x=InflowToUse, y=Duration, label = zStorage, size=5),angle=0)
#geom_contour(data=dfDummyVertical, aes(x=InflowToUse, y= Duration, z = zStorage), binwidth=2, size=1.5)   +
#geom_text_contour(data=dfDummyVertical, aes(x=InflowToUse, y= Duration, z = zStorage), binwidth=2, size=6, check_overlap = TRUE, min.size = 5) +
#Overplot the data points
#geom_point(data=dfDummyVertical, aes(x=InflowToUse, y= Duration), color="Black", size = 5)
### Lee Ferry Flow plot with paleo events marked
# Read in the paleo flow data from Excel
sPaleoFile <- 'DroughtDurations.xlsx'
dfPaleoEvents <- read_excel(sPaleoFile, sheet = "Sheet1",  range = "A4:E18")
#Order the data frame by Flow
dfPaleoEvents <- dfPaleoEvents[order(dfPaleoEvents$`Average Flow (maf)`),]
dfPaleoEvents$YearRange <- paste(dfPaleoEvents$`Start Year`," to ",dfPaleoEvents$`End Year`)
dfDurations <- dfTimeInflowStorageResultsClean %>% filter(Status == "Bottom")
cLeeFlows <- unique(sort(dfDurations$InflowToUse))
cDurs <- unique(sort(dfDurations$index))
nDurs <- length(cDurs)
nLeeFlows <- length(cLeeFlows)
#Create a matrix of the storages for a particular Flow and Duration
mStors <- matrix(0, nrow = nLeeFlows, ncol = nDurs)
#Assign the right values to mgridStors
for (i in (1:nLeeFlows)) {
iFlow <- cFlows[i]
for (j in (1:nDurs)) {
iDur <- cDurs[j]
dfTempRecord <- dfDurations %>% filter(InflowToUse == iFlow, index == iDur)
mStors[i,j] <- ifelse(nrow(dfTempRecord)==0,tMaxVol*1e6,dfTempRecord$InitStorage)
}
}
#Loop through the Paleo events and interpolate a storage for the specified flow and duration
dfPaleoEvents$InitStor <- interp2(x=cDurs, y=cLeeFlows, Z = mStors/1e6, xp=dfPaleoEvents$`Length (years)`, yp=dfPaleoEvents$`Average Flow (maf)`*1e6, "linear")
## Draw the plot
# Rebring the code and integrate points/labels earlier
# Only use start year
# For events with start-storage larger than 25 MAF or greater than 12.3 MAF per year inflow, plot at
#     top as second y axis
library(ggrepel)
## Add another layer to the plot which is the points
pPlot <- pPlot +
geom_point(data=dfPaleoEvents, aes(x=`Average Flow (maf)`, y=InitStor), size=5) +
geom_text_repel(data=dfPaleoEvents, aes(x=`Average Flow (maf)`, y=InitStor, label=dfPaleoEvents$YearRange), size = 5)
print(pPlot)
############################################################
##
## What steady reservoir releases over a specified number of years will keep the reservoir above a target storage level given a steady inflow and starting storage?
##
#########################################
#Define the function to calculate
SteadyRelease <- function(StartStorage,TargetStorage,SteadyInflow,NumYears,eRate,ResArea,ResVolume,StorageErrorCrit) {
#StartStorage = starting reservoir storage volume
#TargetStorage = target reservoir storage volume
#SteadyInflow = steady inflow volume each and every year
#NumYears = Number of years to reach the storage target
#eRate = evaporation rate in length/year
#ResArea = reservoir area from bathymetry curve
#ResVolume = reservoir volume from bathymetry curve
#StorageErrorCrit = the storage volume error criteria. When the difference between the simulated final reservoir storage value
#       obtained with the steady release and the target storage falls below this criteria, the routine will
#       stop iterating to find a new steady release value.
#The guiding formula is:
#     [Storage Target] = [Start Storage] + [Num Years] * ([Inflow] - [Release] - [Evaporation])
# Solving for Release and noting Evaporation is an average of evaporation in Year 1, Year 2, ..., Year n
#     [Release] = [Inflow] - (Evap_1 + Evap_2 + ... + Evap_n - [Storage Target] + [Start Storage])/[Num Years]
# Calculate evaporation volumes in each year as a linear interpolation off the reservoir bathymetry curve from
# each expected reservoir storage volume
# Expected storage volumes
sVols <- seq(StartStorage,TargetStorage,by=(TargetStorage-StartStorage)/NumYears)
#evaporation volumes
evaps <- eRate*interpNA(x=ResVolume, y=ResArea,xi = sVols)
#print(sVols)
#print(evaps)
#Now calculate the steady annual release. Two vresions. One when Start and Target Storage are above
#The critical threshold. A second when they are below (no change in storage, steady storage)
if (abs(StartStorage - TargetStorage) > StorageErrorCrit) {
#When Start and Target storage are different
CurrSteadyRelease <- SteadyInflow - (sum(evaps) - StartStorage + TargetStorage) / NumYears
} else {
#When start storage and target storage are numerically the same
CurrSteadyRelease <- SteadyInflow - evaps[1]
}
#print(CurrSteadyRelease)
maxVol = max(ResVolume) #Maximum volume of reservoir
#Simulate the steady release, determine the actual ending storage, and check for differences
#between the simulated storage and target storage that are larger than the StorageErrorCrit
#If the error is above the StorageErrorCrit iterate to reduce the difference below the StorageErrorCritSet the initial
#Start the difference above the StorageErrorCrit so we enter the while loop at least once
StorageDifference <- StorageErrorCrit + 1
while(StorageDifference > StorageErrorCrit) {
#Simulate the current steady release
tSimTime <- TimeToReservoirTarget(Sinit = StartStorage, inflow = SteadyInflow, deliveryVolume = rep(CurrSteadyRelease,2),
deliveryResStorage = c(0,maxVol), eRate = eRateToUse, ResArea = ResArea,
ResVolume = ResVolume, MaxIts = NumYears+1, sMethodRelease = "constant", sMinTarget = 0, sMaxTarget = maxVol, startYear = 0)
#Pull out the ending storage
SimStorage <- tSimTime$dfTimeResults$Storage[NumYears+1]
#Calculate the difference between the simulated storage and the target storage
StorageDifference <- abs(SimStorage - TargetStorage)
#print(StorageDifference)
if (StorageDifference > StorageErrorCrit) {
#Adjust the Steady Releaset
CurrSteadyRelease <- CurrSteadyRelease + (SimStorage - TargetStorage) / (NumYears)
}
}
SteadyRelease <- CurrSteadyRelease
}
#Test the function
#Case 1: Decline to target
tReleaseTest <- SteadyRelease(StartStorage = 10e6, TargetStorage = 5e6, NumYears = 5, SteadyInflow = 8e6, eRate = eRateToUse,  ResArea = dfMeadElevStor$`Area (acres)`,
ResVolume = dfMeadElevStor$`Live Storage (ac-ft)`, StorageErrorCrit = 10000)
#Case 2: Increase to target
tReleaseTest <- SteadyRelease(StartStorage = 5e6, TargetStorage = 10e6, NumYears = 3, SteadyInflow = 8e6, eRate = eRateToUse,  ResArea = dfMeadElevStor$`Area (acres)`,
ResVolume = dfMeadElevStor$`Live Storage (ac-ft)`, StorageErrorCrit = 10000)
#Simulate the steady release to check
tTimeTo <- TimeToReservoirTarget(Sinit = 5e6, inflow = 8e6, deliveryVolume = rep(tReleaseTest,2),
deliveryResStorage = c(0,25e6), eRate = eRateToUse, ResArea = dfMeadElevStor$`Area (acres)`,
ResVolume =dfMeadElevStor$`Live Storage (ac-ft)`, MaxIts = 50, sMethodRelease = "constant", sMinTarget = 0, sMaxTarget = 25e6, startYear = 2020)
#Calculate the difference between the simulated storage and target storage
tTimeTo$dfTimeResults$Storage[4] - 10e6
##Another test with 1, 1, 5, 4e6
tReleaseTest <- SteadyRelease(StartStorage = 1e6, TargetStorage = 1e6, NumYears = 3, SteadyInflow = 4e6, eRate = eRateToUse,  ResArea = dfMeadElevStor$`Area (acres)`,
ResVolume = dfMeadElevStor$`Live Storage (ac-ft)`, StorageErrorCrit = 10000)
tTimeTo <- TimeToReservoirTarget(Sinit = 1e6, inflow = 4e6, deliveryVolume = rep(3.770e6,2),
deliveryResStorage = c(0,25e6), eRate = eRateToUse, ResArea = dfMeadElevStor$`Area (acres)`,
ResVolume =dfMeadElevStor$`Live Storage (ac-ft)`, MaxIts = 50, sMethodRelease = "constant", sMinTarget = 0, sMaxTarget = 25e6, startYear = 2020)
tTimeTo$dfTimeResults$Storage
### Let's simulate for a large number of scenarios of Initial Storage, Storage Targets, Inflow Scenarios, and Years to reaach the target
#Create the master dataframe of results
dfReleaseSimulations <- data.frame(StartStorage=0, StorageTarget=0, Inflow = 0, Years=0, Release=0)
#Initial Storage scenarios (MAF)
cInitStorageScens <- seq(1,tMaxVol,by=2)*1e6
#Storage targets
cStorageTargets <- seq(1, 15, by=1)*1e6
#Steady Inflow scenarios (MAF per year)
cInflowScens <- seq(4,14, by=1)*1e6
#Years to Target Storage
cYearsToTarget <- seq(1,10, by=1)
#Record the number of scenarios
nFlowScens <- length(cInflowScens)
nInitStorScens <- length(cInitStorageScens)
nYearsToTarget <- length(cYearsToTarget)
#Loop over initial storage values
for (tInitStorage in cInitStorageScens) {
print(tInitStorage)
#Loop over target storage values
for (tStorageTarget in cStorageTargets) {
#Loop over number of years to reach target
for (tNumYears in cYearsToTarget) {
#Loop over steady natural inflow values (stress tests)
for (tInflow in cInflowScens){
paste(tInitStorage, tStorageTarget, tNumYears,tInflow, sep=" ")
tRelease <- SteadyRelease(StartStorage = tInitStorage, TargetStorage = tStorageTarget, NumYears = tNumYears, SteadyInflow = tInflow, eRate = eRateToUse,  ResArea = dfMeadElevStor$`Area (acres)`,
ResVolume = dfMeadElevStor$`Live Storage (ac-ft)`, StorageErrorCrit = 10000)
dfTempRecord <- data.frame(StartStorage=tInitStorage, StorageTarget=tStorageTarget, Inflow = tInflow, Years=tNumYears, Release=tRelease)
dfReleaseSimulations <- rbind(dfReleaseSimulations, dfTempRecord)
}
}
}
}
#Plot as a contour plot of x= steady inflow, y = storage, a horizonal line of the storage target, and contours of release
#Select a target that is the elevation 1025
targetStorageVal <- 8e6 #dfMeadPoolsPlot$stor_maf[4]
YearToUse <- 3
ggplot() +
geom_polygon(data = dfPolyScens, aes(x = Inflow + dfInflowAxes[i,2]/1e6, y = MeadVol/1e6, group = id, fill = as.factor(dfPolyScens$DumVal)), show.legend = F) +
geom_contour(data=dfReleaseSimulations %>% filter(StorageTarget == targetStorageVal, Years == YearToUse), aes(x=Inflow/1e6,y= StartStorage/1e6, z = Release/1e6), binwidth=2, size=1.5)   +
geom_text_contour(data=dfReleaseSimulations %>% filter(StorageTarget == targetStorageVal, Years == YearToUse), aes(x=Inflow/1e6,y= StartStorage/1e6, z = Release/1e6), binwidth=2, size=6, check_overlap = TRUE, min.size = 5) +
#geom_label(data=dfStatusPositions, aes(x = MidInflow/1e6 , y = tMaxVol+2, label = Label, fontface="bold", color=Status), size=6, angle = 0) +
#Label the releases
#geom_label(data=dfReleaseSimulations %>% filter(StorageTarget == targetStorageVal, Years == YearToUse), aes(x=Inflow/1e6,y= StartStorage/1e6, label = round(Release/1e6)), binwidth=4, size=6)   +
#Add a horizontal line for the storage target
geom_hline(yintercept = targetStorageVal/1e6, size = 2) +
#Y-axis: Active storage on left, Elevation with labels on right
#scale_y_continuous(breaks = seq(0,tMaxVol,by=5), labels = seq(0,tMaxVol,by=5), limits = c(0, tMaxVol+3),
#                   sec.axis = sec_axis(~. +0, name = "Mead Level (feet)", breaks = dfMeadPoolsPlot$stor_maf, labels = dfMeadPoolsPlot$labelSecY)) +
#Yaxis: Secondary axis as Mead level with pre-processed zones
scale_y_continuous(breaks = seq(0,tMaxVol,by=5), labels = seq(0,tMaxVol,by=5), limits = c(0, tMaxVol),  sec.axis = sec_axis(~. +0, name = "Elevation (feet)", breaks = dfMeadPoolsPlot2$stor_maf, labels = dfMeadPoolsPlot2$label)) +
scale_x_continuous(breaks = xFlowScaleCurr, labels = xFlowScaleCurr) +
#limits = c(0,as.numeric(dfMaxStor %>% filter(Reservoir %in% c("Mead")) %>% select(Volume))),
#scale_y_continuous(breaks = seq(0,50,by=10), labels = seq(0,50,by=10), limits = c(0, 50)) +
#Color scale for polygons - increasing red as go to lower levels
scale_fill_manual(breaks = c(2,1),values = c(palReds[3],palReds[2]),labels = dfPolyLabel$Label ) +
#scale_fill_manual(guide="Guide2", breaks = c("Top","Middle","Bottom"),values = c("Blue","Green","Red"),labels = c("Fill (years)","Steady volume (maf)","To 1,025 (years)" )) +
scale_color_manual(breaks = c("Top","Middle","Bottom"), values=c("red","purple","blue"), labels=c("To Fill (years)","Steady volume (maf)","To 1,025 (years)")) +
theme_bw() +
scale_size(guide="none") +
labs(x=paste(dfInflowAxes[i,1]," (MAF per year)"), y="Mead Active Storage (MAF)") +
#theme(text = element_text(size=20), legend.title=element_blank(), legend.text=element_text(size=18),
#      legend.position = c(0.8,0.7))
theme(text = element_text(size=20),
legend.position = "none")
View(dfRecoveryCases)
View(dfReleaseToStabilizeMelt)
View(dfTraceLabels)
uninstall_tinytex(force = FALSE, dir = tinytex_root())
library(tinytex)
uninstall_tinytex(force = FALSE, dir = tinytex_root())
uninstall_tinytex(force = FALSE, dir = tinytex_root())
sys.which('pdflatex')
Sys.which('pdflatex')
library(tinytex)
tinytex::install_tinytex()
Sys.which('pdflatex')
install.MikTex()
install.MikTeX()
sTemp <- Sys.which('pdflatex')
sTemp
Sys.which('pdflatex')
View(dfReleaseToStabilize)
View(dfCutbacks)
View(dfCutbacksElev)
View(dfCutbacksVols)
View(dfCutbacksVolsFed)
View(dfCutbacks)
# (release as a function of storage and inflow) and reservoirs.
# Examples for a simple test case, Lake Mead, and Lake Powell.
#
# The overall governing equation is:
#   Storage_t+1 = Storage_t + Inflow - Release - Evaporation loss_t.
# We simply count the numer of iterations until Storage_ t+1 goes to zero or becomes really large.
#
# This is a scenario-based version of analysis by Barnett, T. P., and Pierce, D. W. (2008). "When will Lake Mead go dry?" Water Resources Research, 44(3). https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2007WR006704.
# The scenario-based analysis makes it easier to identify new release policies that are functions of storage AND inflow
# to balance supply and demand over the long term.
#
# Data is drawn from CRSS, analysis of DCP, and other sources as docummented in source Excel files (see below)
# Please report bugs/feedback to:
#
# David E. Rosenberg
# April 15, 2019
# Updated August 2, 2019
# Utah State University
# david.rosenberg@usu.edu
rm(list = ls())  #Clear history
# Load required libraies
if (!require(tidyverse)) {
install.packages("tidyverse", repos="http://cran.r-project.org")
library(tidyverse)
}
if (!require(readxl)) {
install.packages("readxl", repos="http://cran.r-project.org")
library(readxl)
}
if (!require(RColorBrewer)) {
install.packages("RColorBrewer",repos="http://cran.r-project.org")
library(RColorBrewer) #
}
if (!require(dplyr)) {
install.packages("dplyr",repos="http://cran.r-project.org")
library(dplyr) #
}
if (!require(expss)) {
install.packages("expss",repos="http://cran.r-project.org")
library(expss) #
}
if (!require(reshape2)) {
install.packages("reshape2", repos="http://cran.r-project.org")
library(reshape2)
}
if (!require(pracma)) {
install.packages("pracma", repos="http://cran.r-project.org")
library(pracma)
}
if (!require(lubridate)) {
install.packages("lubridate", repos="http://cran.r-project.org")
library(lubridate)
}
if (!require(directlabels)) {
install.packages("directlabels", repo="http://cran.r-project.org")
library(directlabels)
}
if (!require(plyr)) {
install.packages("plyr", repo="http://cran.r-project.org")
library(plyr)
}
if (!require(ggplot2)) {
install.packages("ggplot2", repo="http://cran.r-project.org")
library(ggplot2)
}
# New function MeadInflowToPowellRelease that takes an annual Mead Inflow value and estimates the Annual Powell Release
# Simplistic relationship: just add Grand Canyon tributary inflow
#  [Lee Ferry Natural Flow]  =  [Mead Inflow]  - [0.3 to 0.8 MAF Grand Canyon Tributary inflow](numbers all very rough).
MeadInflowToPowellRelease <- function(MeadInflow,GrandCanyonTrib) {
PowellRelease <- MeadInflow - GrandCanyonTrib;
return(PowellRelease)  ;
}
# New function MeadInflowToLeeFerrylNatural that takes a Mead Inflow value and estimates a Lee Ferry Natural Flow value
# Simplistic relationship between natural flow at Lee Ferry and Mead Flow. I think this is something like:
#  [Lee Ferry Natural Flow]  =  [Mead Inflow]  - [0.3 to 0.8 MAF Grand Canyon Tributary inflow] + [0.6 MAF Powell Evaporation] + [4.5 MAF upper basin consumptive use] (numbers all very rough).
MeadInflowToLeeFerryNatural <- function(MeadInflow,GrandCanyonTrib,PowellEvap,UpperBasinConsumUse) {
LeeFerryNatural <- MeadInflow - GrandCanyonTrib + PowellEvap + UpperBasinConsumUse;
return(LeeFerryNatural)  ;
}
# New function interpNA to return NAs for values outside interpolation range (from https://stackoverflow.com/questions/47295879/using-interp1-in-r)
interpNA <- function(x, y, xi = x, ...) {
yi <- rep(NA, length(xi));
sel <- which(xi >= range(x)[1] & xi <= range(x)[2]);
yi[sel] <- interp1(x = x, y = y, xi = xi[sel], ...);
return(yi);
}
# New function which calculates the number of time periods to reach the reservoir's terminal state (low storage such as dead pool, high storage such top of dam)
# User provides
#   Sinit: an initial storage volume
#   inflow: steady constant inflow in each and every time step
#   delivery schedule (release as a function of...) defined by deliveryVolume and deliveryResStorage
#   sMethodRelease: the interpolation method used by interp1 for reservoir releases
#   eRate: evaporation rate in depth per year
#   reservoir bathymetry of ResArea and ResVolume
#   SminTarget: low storage target (when reached, simulation stops)
#   SmaxTarget: upper storage target (when reached, simulation stops)
#   MaxIts: maximum number of iterations before stopping
#   startYear: first year of simulation to help organize time series results
# Accounting is done using the storage balance equation sCurr_t+1 = Scurr_t + inflow - release - evaporation(sCurr_t) is done on an annual basis.
# OUTPUTS
#   dfTimeResults - data frame of time series results including inflow and storage
#   periods - Number of periods to reach terminal state
#   finalstate - takes the value of either "Upper", "Lower", "Middle" to indicate where the final reservoir storage state is
#
# For sMethodRelease options, see method in https://www.rdocumentation.org/packages/pracma/versions/1.9.9/topics/interp1
TimeToReservoirTarget <- function(Sinit, inflow, deliveryVolume, deliveryResStorage, sMethodRelease, eRate,
ResArea, ResVolume, sMinTarget, sMaxTarget, MaxIts, startYear) {
#Start with zero years
currT <- 1
Scurr <- Sinit #Set current storage volume
#Create empty data frame of results
cReleases <- rep(NA,MaxIts)
dfTimeResults <- data.frame(matrix(NA,nrow=MaxIts,ncol=5))
names(dfTimeResults) <- c("Inflow","Year","index","Storage","Release")
Smax <- min(max(ResVolume),max(deliveryResStorage),sMaxTarget) # Calculate maximum volume at which the simulation will stop. from the Bathymetry and Delivery curves and user provided SmaxTarget
Smin <- max(min(ResVolume),min(deliveryResStorage),sMinTarget) # Calculate minimum volume at which the simulation will stop. from the Bathymetry and Delivery curves and user provided SminTarget
while ((Scurr > Smin) && (currT <= MaxIts) && (Scurr <= Smax)){  #keep looping until storage drops to minimum threshold, storage increases to maximum threshold, or we hit the maximum number of interations
#Record the current storage
dfTimeResults$Storage[currT] <- Scurr
#Calculate mass balance components in current time step at Scurr
release <- interpNA(x=deliveryResStorage, y=deliveryVolume,xi = Scurr, method = sMethodRelease) # release is step function defined in the data
evap <- eRate*interpNA(x=ResVolume, y=ResArea,xi = Scurr) # Evaporation is a linear interpolation off the reservoir bathymetry curve
#Reservoir storage balance equation. New storage = Current Storage + Inflow - release - evaporation
Scurr <- Scurr + inflow - release - evap
cReleases[currT] <- release #Log the current release
currT <- currT + 1 # Advance the time step
}
if (currT < MaxIts) {
#Log the "next" storage
#dfTimeResults$Storage[currT] <- Scurr
}
#Determine the ending storage state
if (Scurr >= Smax) {
sStatus <- "Top"
} else if
(Scurr <= Smin) {
sStatus <- "Bottom"
} else { sStatus <- "Middle"
}
#Further post-processing of results to turn into a time-series data from
#Convert list to column
dfTimeResults$Inflow <- rep(inflow, nrow(dfTimeResults))
#Add calendar years
dfTimeResults$Year <- seq(startYear,startYear+nrow(dfTimeResults)-1)
#Add year index
dfTimeResults$index <- seq(1,1+nrow(dfTimeResults)-1)
#Convert storage as list to number
dfTimeResults$Storage <- as.numeric(dfTimeResults$Storage)
#Log the releases
dfTimeResults$Release <- as.numeric(cReleases)
ReturnList <- list("volume" = Scurr, "periods" = currT - 1, "status" = sStatus, "dfTimeResults" = dfTimeResults)
return(ReturnList)
#return(currT)
}
####  Small example to test the TimeToDeadPool function ######
#                                                            #
##############################################################
tStartVol <- 10
tMaxVol <- 15
tInflow <- 2
dfDeliverySchedule <- data.frame(release = c(2,2,5,5), stor = c(0,2,11,tMaxVol))
dfBath <- data.frame(volume = c(0,3,10,tMaxVol), area = c(1,3,5,6))
tErate <- 0.5
interpNA(x=dfDeliverySchedule$stor, y=dfDeliverySchedule$release, xi = tStartVol, method = "constant")
interpNA(x=dfBath$volume, y=dfBath$area,xi = tStartVol)
#debug(TimeToReservoirTarget)
lTestReturn <- TimeToReservoirTarget(Sinit = tStartVol, inflow = tInflow, deliveryVolume = dfDeliverySchedule$release,
deliveryResStorage = dfDeliverySchedule$stor, eRate = tErate, ResArea = dfBath$area,
ResVolume = dfBath$volume, MaxIts = 50, sMethodRelease = "constant", sMinTarget = 3, sMaxTarget = 15, startYear = 2000)
#############################################################
#      Load Data for LAKE MEAD and LAKE POWELL              #
#############################################################
# Lower Basin Delivery Target for CA, AZ, NV, MX, and losses (maf per year)
vLowerBasinDeliveryTarget <- 9.6e6
###This reservoir data comes from CRSS. It was exported to Excel.
# Read elevation-storage data in from Excel
sExcelFile <- 'MeadDroughtContingencyPlan.xlsx'
dfMeadElevStor <- read_excel(sExcelFile, sheet = "Mead-Elevation-Area",  range = "A4:D676")
dfPowellElevStor <- read_excel(sExcelFile, sheet = 'Powell-Elevation-Area',  range = "A4:D689")
# Read in pre-processes pool definitions for Lake Mead from CSV
dfMeadPoolsPlot2 <- read.csv("dfMeadPoolsPlot2.csv",header=TRUE)
#Evaporation rates from CRSS
#EvapRates <- read_excel(sExcelFile, sheet = 'Data',  range = "P3:S15")
# Evaporation Rates from Schmidt et al (2016) Fill Mead First, p. 29, Table 2 - https://qcnr.usu.edu/wats/colorado_river_studies/files/documents/Fill_Mead_First_Analysis.pdf
dfEvapRates <- data.frame(Reservoir = c("Mead","Mead","Powell"),"Rate ft per year" = c(5.98,6.0, 5.73), Source = c("CRSS","FEIS-2008","Reclamation"), MinRate = c(NA,5.5,4.9), MaxRate = c(NA,6.4, 6.5))
# Define maximum storages
dfMaxStor <- data.frame(Reservoir = c("Powell","Mead"),Volume = c(24.32,25.95))
# Read in Reservoir Pools Volumes / Zones from Excel
dfPoolVols <- read_excel(sExcelFile, sheet = "Pools",  range = "D31:O43")
# Read in Reserved Flood Storage
dfReservedFlood <- read_excel(sExcelFile, sheet = "Pools",  range = "C46:E58")
#Convert dates to months
dfReservedFlood$month_num <- month(as.POSIXlt(dfReservedFlood$Month, format="%Y-%m-%Y"))
# Read in Paria, Little Colorado, and Virgin River Flows from CRSS DMI to convert Inflow to Mead to Natural Flow at Lee Ferry
sExcelFileGrandCanyonFlow <- 'HistoricalNaturalFlow.xlsx'
#dfGCFlows <- read_excel(sExcelFileGrandCanyonFlow, sheet = 'Total Natural Flow',  range = "V1:Y1324")
dfGCFlows <- read_excel(sExcelFileGrandCanyonFlow, sheet = 'Total Natural Flow',  range = "U1:Z1324")
dfGCDates <- read_excel(sExcelFileGrandCanyonFlow, sheet = 'Total Natural Flow',  range = "A1:A1324")
#Merge and combine into one Data frame
dfGCFlows$Date <- dfGCDates$`Natural Flow And Salt Calc model Object.Slot`
dfGCFlows$Year <- year(dfGCFlows$Date)
dfGCFlows$Month <- month(as.Date(dfGCFlows$Date,"%Y-%m-%d"))
dfGCFlows$WaterYear <- ifelse(dfGCFlows$Month >= 10,dfGCFlows$Year,dfGCFlows$Year - 1)
#Just tribs
#dfGCFlows$Total <- dfGCFlows$`CoRivPowellToVirgin:PariaGains.LocalInflow` + dfGCFlows$`CoRivPowellToVirgin:LittleCoR.LocalInflow` +
#                          dfGCFlows$VirginRiver.Inflow
#Tribs + Gains above Hoover
dfGCFlows$Total <- dfGCFlows$`CoRivPowellToVirgin:PariaGains.LocalInflow` + dfGCFlows$`CoRivPowellToVirgin:LittleCoR.LocalInflow` +
dfGCFlows$VirginRiver.Inflow + dfGCFlows$`CoRivVirginToMead:GainsAboveHoover.LocalInflow` - dfGCFlows$`CoRivPowellToVirgin:GainsAboveGC.LocalInflow`
#Convert to Water Year and sum by water year
dfGCFlowsByYear <- aggregate(dfGCFlows$Total, by=list(Category=dfGCFlows$WaterYear), FUN=sum)
dfLeeFerryByYear <- aggregate(dfGCFlows$`HistoricalNaturalFlow.AboveLeesFerry`, by=list(Category=dfGCFlows$WaterYear), FUN=sum)
#Change the Names
colnames(dfGCFlowsByYear) <- c("WaterYear","GCFlow")
colnames(dfLeeFerryByYear) <- c("WaterYear", "LeeFerryFlow")
dfGCFlowsByYear$LeeFerryFlow <- dfLeeFerryByYear$LeeFerryFlow
#Calculate the median value
vMedGCFlow <- median(dfGCFlowsByYear$GCFlow)
# Read in the ISG and DCP cutbacks from Excel
dfCutbacksElev <- read_excel(sExcelFile, sheet = "Data",  range = "H21:H41") #Elevations
dfCutbacksVols <- read_excel(sExcelFile, sheet = "Data",  range = "N21:U41") #ISG and DCP for states + MX
dfCutbacksVolsFed <- read_excel(sExcelFile, sheet = "Data",  range = "Y21:Y41") # Federal cutback
#Merge into one data frame
dfCutbacks <- dfCutbacksElev
dfCutbacks$RowNum <- 0
dfCutbacksVols$RowNum <- 0
dfCutbacksVolsFed$RowNum <- 0
for (CurrRow in 1:nrow(dfCutbacks)) {
dfCutbacks[CurrRow,"RowNum"] <- CurrRow
dfCutbacksVols[CurrRow,"RowNum"] <- CurrRow
dfCutbacksVolsFed[CurrRow,"RowNum"] <- CurrRow
}
dfCutbacks <- full_join(dfCutbacks,dfCutbacksVols)
dfCutbacks <- full_join(dfCutbacks,dfCutbacksVolsFed)
# Convert NAs to Zeros
dfCutbacks <- replace(dfCutbacks,is.na(dfCutbacks),0)
# Calculate Mead Volume from Elevation (interpolate from storage-elevation curve)
dfCutbacks$MeadActiveVolume <- interp1(xi = dfCutbacks$`Mead Elevation (ft)`,x=dfMeadElevStor$`Elevation (ft)` , y=dfMeadElevStor$`Live Storage (ac-ft)`, method="linear")
#Calculate Total Reductions for ISG (use Federal and Mexico dating to 2012 )
dfCutbacks <- dfCutbacks %>% mutate(Total2007ISG = `Mexico Reduction (Minute 319) [2012]`+
`2007-AZ Reduction (ac-ft)` + `2007-NV Reduction (ac-ft)` + `2007-CA Reduction (ac-ft)` +
`DCP Federal Government (ac-ft)`)
#Remove federal amount at 1090 ft since IGS only starts at 1075 ft
dfCutbacks$Total2007ISG[dfCutbacks$`Mead Elevation (ft)` == 1090] <- 0
#Calculate Total Reudctions for DCP
dfCutbacks <- dfCutbacks %>% mutate(TotalDCP = `Mexico Reduction (Minute 319) [2012]`+  `Mexico Reduction (Minute 323) [2017]`+
`DCP-AZ Reduction (ac-ft)` + `DCP-NV Reduction (ac-ft)` + `DCP-CA Reduction (ac-ft)` +
`DCP Federal Government (ac-ft)`)
View(dfCutbacks)
dfReleaseToStabilize
dfTraceLabels
